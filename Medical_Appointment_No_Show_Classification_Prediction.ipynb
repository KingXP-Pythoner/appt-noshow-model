{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRN0AsMsAEnz"
      },
      "source": [
        "# Data Mining/Machine Learning Project: Medical Appointments - No Show\n",
        "\n",
        "## Goals\n",
        "1. Given a set of attributes/factors, predict if a person will miss their appointment or not.\n",
        "2. Determine what factors contribute the most to a person missing their appointment.\n",
        "3. Compare the performance of the 2 data mining/analysis methods implemented for this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B5qag8eBvod"
      },
      "source": [
        "##I. Business Understanding\n",
        "\n",
        "Missed appointments are costly on the medical institutions. Therefore, understanding the factors that cause no-shows are vital in the search for potential solutions to these problems. Having the information about the data set have the following benefits:\n",
        "\n",
        "1. Hospital can intelligently send more reminders to patients at a higher risk of missing appointments.\n",
        "2. Understand if the reminder methods (in this case: SMS) are effective or not, and make changes as necessary to the strategies.\n",
        "3. Inform appointment management/scheduling strategy. (More on the day or more routine appointments?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfOJoig3HljX"
      },
      "source": [
        "## II. Data Understanding\n",
        "### Dataset:\n",
        "The dataset contains information about medical appointments and has 14 variables (PatientId, AppointmentID, Gender, DateScheduled, AppointmentDate, Age, Neighborhood, Scholarship, Hypertension, Diabetes, Alcoholism, Handicap, SMSReceived, NoShow).\n",
        "\n",
        "### Tasks:\n",
        "\n",
        "Explore the dataset to understand its structure, size, and features.\n",
        "Check for missing values, outliers, and data types.\n",
        "Understand the distribution of the target variable (NoShow).\n",
        "Explore and analyze the relationships between features and the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZAmQYfwNg4g"
      },
      "outputs": [],
      "source": [
        "# Load the required libraries\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('display.width', 1000)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data into a pandas dataframe\n",
        "df = pd.read_csv('dataset.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Size, Dimensionality, Size, Data types\n",
        "The dataset provided by [source] has a 110527 x 14 (mxn) dimensionality. We can identify the following columns and their data types (as nominal, ordinal, or continuous):\n",
        "1. PatientId: nominal\n",
        "2. AppointmentID: nominal\n",
        "3. Gender: nominal\n",
        "4. ScheduledDay: date type\n",
        "5. AppointmentDay: date type\n",
        "6. Age: continuous\n",
        "7. Neighbourhood: nominal\n",
        "8. Scholarship: nominal\n",
        "9. Hypertension: nominal\n",
        "10. Diabetes: nominal\n",
        "11. Alcoholism: nominal\n",
        "12. Handcap: nominal\n",
        "13. SMS_received: nominal\n",
        "14. No-show: nominal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset shape\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First 5 rows of the dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset has 14 columns or characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List columns in the dataset\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Duplication check\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataframe overall information\n",
        "The dataset has no missing values across all rows and columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df.drop(columns=['AppointmentID'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## rename columns to fix typos and use pythonic naming conventions\n",
        "column_rename_dict = {}\n",
        "for column in df.columns:\n",
        "    column_rename_dict[column] = column.lower().replace(' ', '_')\n",
        "    if '-' in column_rename_dict[column]:\n",
        "        column_rename_dict[column] = column_rename_dict[column].replace('-', '_')\n",
        "\n",
        "column_rename_dict['Hipertension'] = 'hypertension'\n",
        "column_rename_dict['Handcap'] = 'handicap'\n",
        "column_rename_dict['AppointmentDay'] = 'appointment_day'\n",
        "column_rename_dict['ScheduledDay'] = 'scheduled_day'\n",
        "column_rename_dict['PatientId'] = 'patient_id'\n",
        "\n",
        "df.rename(columns=column_rename_dict, inplace=True)\n",
        "# Check\n",
        "df.columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Descriptive Statistics\n",
        "1. Minimum age is -1 which is not possible.\n",
        "2. Scholarship, Hypertension, Diabetes are binary for all rows. But Handicap has a max value of 4. This could mean this attribute should be binary and these >1 values are errors or it means the number of handicaps the patient had. The description provided from the source via Kaggle states it should be represented as True or False, but the Discussions revealed the attribute is the number of handicaps the patient has."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.select_dtypes(exclude='object').columns.drop([\"patient_id\"])].describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols_no_age = df.select_dtypes(exclude='object').columns.drop(['patient_id', 'age'])\n",
        "\n",
        "# Concatenate the percentage distribution data for all columns\n",
        "perc_dist = pd.concat([pd.DataFrame({f\"{column} value\": df[column].value_counts(normalize=True).index,\n",
        "                                                f\"{column} percentage %\": (df[column].value_counts(normalize=True) * 100).round(4).values})\n",
        "                                  for column in num_cols_no_age], axis=1)\n",
        "perc_dist = perc_dist.fillna(0)\n",
        "\n",
        "perc_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning\n",
        "The goal is to remove anomalies from the data to develop data quality. Since in the descriptive statistics check an anomaly was observed in both the age and handicap columns, data cleaning operation can be performed in these columns. We can also ensure date type columns are converted correctly to datetime.\n",
        "### Steps:\n",
        "1. Remove the row will the age = -1. Manual removal is done here as it is simply 1 record with this issue and will not significantly impact the age column in correlation to the target variable for data modeling.\n",
        "2. Convert scheduled_day and appointment_day columns to datetime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove rows with negative age\n",
        "df.query(\"age == -1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if there are enough rows in the dataset for ROMÃO. If that's the case, the loss is negligible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(df[df['neighbourhood'] ==  \"ROMÃO\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop row with negative age\n",
        "from matplotlib import axis\n",
        "\n",
        "\n",
        "negative_age_idx = df[df[\"age\"] == -1].index\n",
        "df.drop(negative_age_idx, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the scheduled_day and appointment_day columns to datetime\n",
        "df['scheduled_day'] = pd.to_datetime(df['scheduled_day'])\n",
        "df['appointment_day'] = pd.to_datetime(df['appointment_day'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nominal_columns = df.select_dtypes(include='object').columns\n",
        "numerical_columns =df.select_dtypes(exclude='object').columns\n",
        "\n",
        "nominal_cols_list = nominal_columns.tolist()\n",
        "num_cols_list = numerical_columns.tolist()\n",
        "numerical_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.columns.drop(['patient_id', 'appointment_day', 'scheduled_day'])].hist(figsize=(16,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Age Group Distribution\n",
        "From plotting age distribution on a bar chart, baby (0 years) patients have the most frequency. The distribution is slightly left skewed meaning only a minority sample of the patient population in the dataframe were of the senior/elderly population."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Discretize the Age column into bins\n",
        "age_bins = [0, 18, 30, 45, 60, 75, 100]\n",
        "age_labels = ['0-17', '18-29', '30-44', '45-59', '60-74', '75-100']\n",
        "age_group_df = pd.cut(df['age'], bins=age_bins, labels=age_labels, right=False)\n",
        "\n",
        "# Calculate age group counts and percentages\n",
        "age_group_counts = age_group_df.value_counts().sort_index()\n",
        "age_group_percentages = (age_group_counts / age_group_counts.sum()) * 100\n",
        "\n",
        "# Prepare the data for plotting\n",
        "plot_data = pd.DataFrame({'AgeGroup': age_group_counts.index, 'Count': age_group_counts.values, 'Percentage': age_group_percentages.values})\n",
        "\n",
        "# Plot the bar chart\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=plot_data, x='AgeGroup', y='Count', palette='pastel', hue='AgeGroup', dodge=False)\n",
        "plt.legend([],[], frameon=False)  # Hide the legend\n",
        "\n",
        "# Add percentages on top of bars\n",
        "for i, (count, percentage) in enumerate(zip(plot_data['Count'], plot_data['Percentage'])):\n",
        "    plt.text(i, count, f'{percentage:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.title('Age Group Distribution')\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show = df['no_show'] == 'No'\n",
        "no_show = df['no_show'] == 'Yes'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot histograms for age based on attendance\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Histogram for age of patients who showed up\n",
        "plt.hist(df['age'][show], bins=18, color='green', alpha=0.5,  label='Showed up')\n",
        "# Histogram for age of patients who didn't show up\n",
        "plt.hist(df['age'][no_show], bins=18, alpha=0.5, color='red', label='No show')\n",
        "\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.title('Attendance by Age')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison of attendance between genders (Male and Female)\n",
        "\n",
        "The analysis shows that 64.9% of females attended their appointments versus 35.1% of males, and 65.39% of females did not attend versus 34.61% of males. This indicates that while the dataset is skewed towards females, gender here is not a strong predictor of no-show behavior due to the similar percentage distributions across both attendance and no-shows. Consequently, to achieve the project's aim of improving attendance rates, it is crucial to explore other variables such as age, medical conditions, and the impact of SMS reminders, which may provide stronger correlations and insights into patient attendance patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "gender_showed = df[show]['gender'].value_counts(normalize=True)\n",
        "gender_no_show = df[no_show][\"gender\"].value_counts(normalize=True)\n",
        "\n",
        "colors = ['lightgreen', 'lightcoral']\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "gender_showed.plot(kind='pie', autopct='%1.1f%%',ax=axes[0], colors=colors)        \n",
        "axes[0].set_title('Percentage of gender that attended', fontdict={'fontsize':12})\n",
        "axes[0].set_ylabel('')\n",
        "\n",
        "gender_no_show.plot(kind='pie', autopct='%1.1f%%',ax=axes[1], colors=colors) \n",
        "axes[1].set_title('Percentage of gender that did not show up', fontdict={'fontsize': 12})\n",
        "axes[1].set_ylabel('')\n",
        "\n",
        "plt.show()       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison of attendance by chronic disease\n",
        "(Note to self): Get reference for alcoholism definition as a chronic disease.\n",
        "In exploring the correlation between chronic diseases and appointment attendance, our objective is to understand whether patients with chronic conditions may demonstrate distinct attendance patterns compared to those without such ailments. The analysis unveils a noticeable contrast in attendance rates, with 82.23% of patients with chronic diseases attending appointments versus 79.09% of those without. Conversely, 17.77% of patients with chronic diseases missed appointments, while 20.91% of those without chronic diseases did.\n",
        "\n",
        "This disparity, a 3.14% difference in attendance rates, although may be thought of being relatively small, slightly suggests that ongoing health management may influence attendance behavior, providing insights for healthcare providers to tailor interventions and enhance appointment adherence across patient groups. However, the scale of this influence may not be determined yet as the data collection occured in a short time period. A longer time frame collection may yield better clarity in understanding this influence. But for the goal of the data exploration and modeling, chronic diseases such as hypertension, diabetes and alcoholism do not show a noteworthy correlation with appointment adherence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new column to indicate if a patient has any chronic disease\n",
        "dfc = df.copy(deep=True)\n",
        "dfc['has_chronic_disease'] = dfc[['hypertension', 'diabetes', 'alcoholism']].sum(axis=1) > 0\n",
        "\n",
        "# Calculate the counts of no-shows and shows for patients with and without chronic diseases\n",
        "comparison = dfc.groupby(['has_chronic_disease', 'no_show']).size().unstack().fillna(0)\n",
        "\n",
        "# Plot the bar chart\n",
        "ax = comparison.plot(kind='bar', stacked=True, color=['lightgreen', 'lightcoral'], figsize=(9, 7))\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Chronical Disease Status')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Attendance Comparison: Patients with and without Chronic Diseases')\n",
        "ax.set_xticklabels(['No Chronic Disease', 'Has Chronic Disease'], rotation=0)\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the counts of no-shows and shows for patients with and without chronic diseases\n",
        "attendance_comparison = dfc.groupby(['has_chronic_disease', 'no_show']).size().unstack().fillna(0)\n",
        "\n",
        "# Calculate percentages\n",
        "attendance_percentages = attendance_comparison.div(attendance_comparison.sum(axis=1), axis=0) * 100\n",
        "\n",
        "# Prepare data for printing as a table\n",
        "table_data = [\n",
        "    [\"Chronic Disease\", \"No-show\", \"Show\"],\n",
        "    [False, attendance_comparison.loc[False, 'Yes'], attendance_comparison.loc[False, 'No']],\n",
        "    [True, attendance_comparison.loc[True, 'Yes'], attendance_comparison.loc[True, 'No']],\n",
        "]\n",
        "\n",
        "# Print table headers\n",
        "print(\"Counts of Attendance for Patients with and without Chronic Diseases:\")\n",
        "# Print table rows\n",
        "for row in table_data:\n",
        "    print(\"{:<17} | {:<7} | {:<5}\".format(*row))\n",
        "\n",
        "print(\"\\nPercentages of Attendance for Patients with and without Chronic Diseases:\")\n",
        "# Print percentages\n",
        "print(attendance_percentages.round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attendance comparison based on SMS received\n",
        "In analyzing the correlation between SMS reception and appointment attendance, our aim is to discern whether patients who receive SMS reminders exhibit different attendance behavior compared to those who don't. The results reveal a notable difference in attendance rates: 83.30% of patients who did not receive an SMS reminder attended their appointments, while 16.70% did not. The discrepancy show that sending SMS reminders actually had an opposite outcome of the expectation that the reminders would improve attendance. However, we need to investigate how same-day appointments contributes to these findings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='sms_received', hue='no_show', data=df, palette='pastel')\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('SMS Received', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.title('Attendance comparison based on SMS Reception', fontsize=14)\n",
        "\n",
        "# Show plot\n",
        "plt.legend(title='Attended', labels=['Yes', 'No'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the percentages of show and noshow instances for each category of SMS reception\n",
        "perc_sms_show = df.groupby('sms_received')['no_show'].value_counts(normalize=True)[:, 'No'] * 100\n",
        "perc_sms_noshow = df.groupby('sms_received')['no_show'].value_counts(normalize=True)[:, 'Yes'] * 100\n",
        "\n",
        "# Prepare data for printing as a table\n",
        "table_data = []\n",
        "for sms_received, show_percentage, noshow_percentage in zip(perc_sms_show.index, perc_sms_show.values, perc_sms_noshow.values):\n",
        "    table_data.append([sms_received, show_percentage, noshow_percentage])\n",
        "\n",
        "# Print table headers\n",
        "print(\"SMS Received | Show Percentage | Noshow Percentage\")\n",
        "# Print table rows\n",
        "for row in table_data:\n",
        "    print(\"{:<12} | {:<15.2f}% | {:<15.2f}%\".format(*row))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Same day appointments statistics\n",
        "Roughly 35% of all appointments recorded were same-day appointments. This distribution is significant enough to influence the results gathered earlier. Therefore, it is necessary to filter out same-day appointments as this will be the real test of the impact of the sms campaign."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "is_same_day = (df['scheduled_day'].dt.date == df['appointment_day'].dt.date) & (df['scheduled_day'].dt.month == df['appointment_day'].dt.month)\n",
        "same_day_appts = df[is_same_day == True]\n",
        "same_day_appts_count = same_day_appts.value_counts().sum()\n",
        "# Non-same day appointments\n",
        "not_same_day_appts = df[is_same_day == False]\n",
        "\n",
        "print(f\"Number of appointments scheduled on the same day: {same_day_appts_count}\")\n",
        "print(f\"Percentage of appointments scheduled on the same day: {(same_day_appts_count / df.shape[0]) * 100:.4f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "not_same_day_appts_count = not_same_day_appts.value_counts().sum()\n",
        "print(f\"Number of appointments scheduled on different days: {not_same_day_appts_count}\")\n",
        "not_same_day_appts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 9))\n",
        "sns.countplot(x='sms_received', hue='no_show', data=not_same_day_appts, palette='pastel')\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('SMS Received', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.title('Attendance comparison based on SMS Reception', fontsize=14)\n",
        "\n",
        "# Show plot\n",
        "plt.legend(title='Attended', labels=['Yes', 'No'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After filtering out same-day appointments, the new analysis revealed that patients who did not receive an SMS had a show percentage of 70.55% and a no-show percentage of 29.45%. Those who received an SMS showed a slight increase in attendance, with a show percentage of 72.43% and a no-show percentage of 27.57%. This suggests that, for non-same-day appointments, receiving an SMS has a modest positive impact on attendance, improving the show rate by approximately 2% compared to those who did not receive an SMS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the percentages of show and noshow instances for each category of SMS reception for non-same day appointments\n",
        "perc_sms_show = not_same_day_appts.groupby('sms_received')['no_show'].value_counts(normalize=True)[:, 'No'] * 100\n",
        "perc_sms_noshow = not_same_day_appts.groupby('sms_received')['no_show'].value_counts(normalize=True)[:, 'Yes'] * 100\n",
        "\n",
        "# Prepare data for printing as a table\n",
        "table_data = []\n",
        "for sms_received, show_percentage, noshow_percentage in zip(perc_sms_show.index, perc_sms_show.values, perc_sms_noshow.values):\n",
        "    table_data.append([sms_received, show_percentage, noshow_percentage])\n",
        "\n",
        "# Print table headers\n",
        "print(\"SMS Received | Show Percentage | Noshow Percentage\")\n",
        "# Print table rows\n",
        "for row in table_data:\n",
        "    print(\"{:<12} | {:<15.4f}% | {:<15.4f}%\".format(*row))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attendance comparison by Handicap\n",
        "\n",
        "Based on the analysis of attendance comparison based on the level of handicap, we observe varying trends. The majority of appointments involve patients with no reported handicap, comprising approximately 97.97% of the dataset. Among these appointments, the no-show rate is 20.24%, indicating a moderate but notable proportion of missed appointments. Interestingly, appointments involving patients with a reported handicap level of 1 or 2 exhibit slightly lower no-show rates compared to those with no reported handicap, suggesting a potential correlation between a mild level of handicap and increased appointment attendance. However, caution is warranted in interpreting these findings due to the relatively small sample sizes of patients with higher levels of handicap (levels 3 and 4), which may not be representative. Further investigation with larger datasets or stratified analyses by handicap severity may provide deeper insights into the relationship between handicap level and appointment attendance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the counts for show and no-show for each handicap level\n",
        "handicap_attendance_counts = df.groupby(['handicap', 'no_show']).size().unstack().fillna(0)\n",
        "\n",
        "# Plot the bar chart\n",
        "handicap_attendance_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['lightgreen', 'lightcoral'])\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Handicap Level')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Attendance Comparison Based on Handicap')\n",
        "plt.legend(title='No-show', loc='upper right', labels=['Show', 'No-show'])\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the total count per handicap level\n",
        "handicap_total_counts = df.groupby('handicap').size()\n",
        "\n",
        "\n",
        "handicap_attendance_counts = df.groupby(['handicap', 'no_show']).size().unstack().fillna(0)\n",
        "\n",
        "handicap_attendance_percentages = handicap_attendance_counts.div(handicap_total_counts, axis=0) * 100\n",
        "\n",
        "handicap_summary = pd.DataFrame({\n",
        "    'Handicap Level': handicap_total_counts.index,\n",
        "    'Total Count': handicap_total_counts.values,\n",
        "    'Show Count': handicap_attendance_counts['No'].values,\n",
        "    'Noshow Count': handicap_attendance_counts['Yes'].values,\n",
        "    'Show Percentage': handicap_attendance_percentages['No'].values,\n",
        "    'Noshow Percentage': handicap_attendance_percentages['Yes'].values\n",
        "})\n",
        "\n",
        "# Print the summary table\n",
        "print(handicap_summary.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attendance Comparison based on Scholarship status\n",
        "\n",
        "We observe that the majority of patients without scholarship status attended their appointments, with an attendance rate of 80.19%. Conversely, patients with scholarship status had a slightly lower attendance rate of 76.26%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the counts for show and no-show for each scholarship status\n",
        "scholarship_attendance_counts = df.groupby(['scholarship', 'no_show']).size().unstack()\n",
        "\n",
        "# Plot the bar chart\n",
        "scholarship_attendance_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['lightgreen', 'lightcoral'])\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Scholarship Status')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Attendance Comparison Based on Scholarship Status')\n",
        "plt.legend(title='No-show', loc='upper right', labels=['Show', 'No-show'])\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.show()\n",
        "# #does neighbourhood affect the attendance?\n",
        "# plt.figure(figsize=(20,13))\n",
        "# df['scholarship'][show].value_counts().plot(kind='bar', color = 'blue', label = 'show')\n",
        "# df['scholarship'][no_show].value_counts().plot(kind='bar', color = 'red', label = 'noShow')\n",
        "# plt.legend()\n",
        "# plt.title('comparison according to Neighbourhood')\n",
        "# plt.xlabel('Neighbourhood')\n",
        "# plt.ylabel('Patient No.')\n",
        "\n",
        "scholarship_attendance_counts.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.groupby('scholarship').size().sum())\n",
        "df.groupby('scholarship')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the total count per scholarship status\n",
        "scholarship_total_counts = df.groupby('scholarship').size()\n",
        "scholarship_attendance_perc = scholarship_attendance_counts.div(scholarship_total_counts, axis=0) * 100\n",
        "\n",
        "scholarship_summary = pd.DataFrame({\n",
        "    'Scholarship Status': scholarship_total_counts.index,\n",
        "    'Total Count': scholarship_total_counts.values,\n",
        "    'Show Count': scholarship_attendance_counts['No'].values,\n",
        "    'Noshow Count': scholarship_attendance_counts['Yes'].values,\n",
        "    'Show Percentage': scholarship_attendance_perc['No'].values,\n",
        "    'Noshow Percentage': scholarship_attendance_perc['Yes'].values\n",
        "})\n",
        "\n",
        "print(scholarship_summary.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attendance comparison based on Neighborhood\n",
        "\n",
        "The variability in the percentages of attendance per neighbourhood shows neighbourhood has a strong effect on attendance, perhaps more than other features explored in this analysis. This may be the factor that contributes most to attendance and this might need to be investigated further, although that is beyond the scope of the data analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#does neighbourhood affect the attendance?\n",
        "plt.figure(figsize=(20,10))\n",
        "df['neighbourhood'][show].value_counts().plot(kind='bar', color = 'lightgreen', label = 'show')\n",
        "df['neighbourhood'][no_show].value_counts().plot(kind='bar', color = 'lightcoral', label = 'no show')\n",
        "plt.legend()\n",
        "plt.title('comparison according to Neighbourhood')\n",
        "plt.xlabel('Neighbourhood')\n",
        "plt.ylabel('Patient No.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by neighborhood and no_show, calculate counts\n",
        "neighborhood_counts = df.groupby(['neighbourhood', 'no_show']).size().unstack().fillna(0)\n",
        "\n",
        "# Calculate total count per neighborhood\n",
        "total_counts = neighborhood_counts.sum(axis=1)\n",
        "\n",
        "# Sort neighborhoods by total count in descending order\n",
        "sorted_neighborhood_counts = neighborhood_counts.loc[total_counts.sort_values(ascending=False).index]\n",
        "\n",
        "# Calculate percentages\n",
        "neighborhood_percentages = (sorted_neighborhood_counts.div(sorted_neighborhood_counts.sum(axis=1), axis=0) * 100).round(2)\n",
        "\n",
        "# Prepare the data for printing\n",
        "data = {\n",
        "    'Neighborhood': sorted_neighborhood_counts.index,\n",
        "    'Total Count': sorted_neighborhood_counts.sum(axis=1),\n",
        "    'Show Count': sorted_neighborhood_counts['No'],\n",
        "    'Noshow Count': sorted_neighborhood_counts['Yes'],\n",
        "    'Show Percentage': neighborhood_percentages['No'],\n",
        "    'Noshow Percentage': neighborhood_percentages['Yes']\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "result_df = pd.DataFrame(data)\n",
        "\n",
        "# Print the table\n",
        "print(result_df.head(15).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class Imbalance Investigation\n",
        "There is a significant imbalance between the classes as over 88k patients attended their appointments versus over 22k missing their appointments. A similar imbalance still appears even after filtering out same-day appointments as it was already known that 35% of the appointments were same-day appointments which majorly were shows (No in no_show class). This occurence must be considered during data modeling. This also means the metric for model quality may not be accuracy and might be other metrics like F1 Score and ROC AUC. Another possible technique that can be implemented could be Random Undersampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['no_show'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Investigate the class imbalance in the dataset (no-shows vs shows) and plot the distribution on one bar chart\n",
        "\n",
        "sns.countplot(x='no_show', data=df, palette='pastel')\n",
        "plt.title(\"Classes distribution\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check class imbalance if same day appointments are removed  and plot the distribution on one bar chart\n",
        "sns.countplot(x='no_show', data=not_same_day_appts, palette='pastel')\n",
        "plt.title(\"Classes distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Ratio of shows to no-shows\n",
        "no_show_ratio = df['no_show'].value_counts(normalize=True)['Yes'] / df['no_show'].value_counts(normalize=True)['No']\n",
        "no_show_ratio = round(no_show_ratio, 2)\n",
        "print(f'Ratio of shows to no-shows: {no_show_ratio.as_integer_ratio()[1]}:{no_show_ratio.as_integer_ratio()[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Modelling\n",
        "As we proceed with the data modeling stage, two data modeling techniques were chosen for predicting if a patient will miss their appointments or not. The model techniques used are:\n",
        "1. Logistic Regression Classifier\n",
        "2. Neural Network Classifier\n",
        "\n",
        "This is the order of steps that will be followed:\n",
        "1. Perform feature engineering.\n",
        "    - Convert categorical features to numerical. This can be done via one hot encoding.\n",
        "    - Create new features as needed.\n",
        "    - Perform feature selection.\n",
        "3. Split dataset into training, validation and testing sets.\n",
        "4. Design and train the models on the training set and hypertune with validation set.\n",
        "5. Evaluate the model's performance via accuracy, F1, confusion matrix and ROC AUC results from testing set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Convert categorical features to numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfm = df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop rows where the values of the handicap column are greater than 1\n",
        "dfm.drop(dfm[dfm['handicap'] > 1].index, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Male and Female numerical columns from gender column\n",
        "dfm['is_male'] = dfm['gender'].map({'M': 1, 'F': 0})\n",
        "\n",
        "# Convert the target variable column\n",
        "dfm['no_show'] = dfm['no_show'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Drop the gender column\n",
        "dfm.drop(columns=['gender'], inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### We have neighbourhood column with high cardinality. Using one-hot encoding will increase the number of columns significantly. Therefore, we can use frequency encoding to encode the neighbourhood column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First check if there are any labels in the neighbourhood column that have the same count.\n",
        "track_count = 0\n",
        "for count in dfm['neighbourhood'].value_counts().value_counts():\n",
        "    if count > 1:\n",
        "        track_count += 1\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "if track_count > 0:\n",
        "    print(f'{'-'*10}There are labels with the same count. Valuable information may be lost.{'-'*10}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the frequency of each category\n",
        "freq = dfm['neighbourhood'].value_counts(normalize=True)\n",
        "\n",
        "# Map the frequencies to the dataframe\n",
        "dfm['neighbourhood_encoded'] = dfm['neighbourhood'].map(freq)\n",
        "\n",
        "# Drop the neighbourhood column\n",
        "dfm.drop(columns=['neighbourhood'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the Age column\n",
        "_numerical_columns = dfm.select_dtypes(exclude='object').columns.drop(['patient_id', 'scheduled_day', 'appointment_day'])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "normalized = scaler.fit_transform(dfm[_numerical_columns])\n",
        "dfm['age_normalized'] = pd.DataFrame(normalized, columns=_numerical_columns)['age']\n",
        "\n",
        "dfm.drop(columns=['age'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection\n",
        "\n",
        "Before modeling, we need to select what features may contribute the most information gain to the model, i.e correlates with the target variables. From the dataset, most of the features are binary, including the target variables. For categorical input features with categorical output/target, a well-known method for determining the correlation is called Chi-Square Test. However, we have converted the neighbourhood and age features to non-binary numerical features. For these columns, we may need to apply a different correlation discovery technique called Pearson Correlation Coefficient.\n",
        "\n",
        "## Chi Square \n",
        "I will select the best 3 features with the highest importance from the results of conducting the Chi Square. This works by choosing the three features with the highest chi values and lowest p values.\n",
        "\n",
        "# Pearson Correlation Coefficient\n",
        "As there are only 2 input features,adding to the previously selected 3 features from the Chi-Square test gives 5 features which is not too much for the model. So after visualization, we can add both features as inputs for the models and evaluate the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfm.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement Chi-Square for checking correlation between categorical variables and the target variable\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "X = dfm.drop(columns=['no_show', 'patient_id', 'scheduled_day', 'appointment_day', 'neighbourhood_encoded', 'age_normalized'], axis=1)\n",
        "y = dfm['no_show']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chi_scores = chi2(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chi_values = pd.Series(chi_scores[0], index=X.columns)\n",
        "chi_values.sort_values(ascending=False, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Higher the p-value, the more the feature is independent of the target variable\n",
        "\n",
        "p_values = pd.Series(chi_scores[1], index=X.columns)\n",
        "p_values.sort_values(ascending=False, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print Chi and P-values for each feature\n",
        "print(\"Chi and P-values for each feature:\")\n",
        "# Print the table\n",
        "print(pd.concat([chi_values, p_values], axis=1, keys=['Chi', 'P-value']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Higher the chi-squared value, the more the feature is related to the target variable\n",
        "# Plot the chi-squared values using a bar chart. Give a chart title of 'Chi value importance for each feature'\n",
        "chi_values.plot(kind='bar', figsize=(12, 6), color='skyblue')\n",
        "plt.title('Chi value importance for each feature')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the p-values using a bar chart. Give a chart title of 'P-value importance for each feature'\n",
        "p_values.plot(kind='bar', figsize=(12, 6), color='lightcoral')\n",
        "plt.title('P-value importance for each feature')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"white\")\n",
        "non_binary_cols = ['neighbourhood_encoded', 'age_normalized', 'no_show']\n",
        "corr = dfm[non_binary_cols].corr()  # Create the pearson correlation metrix object\n",
        "\n",
        "fig, ax = plt.subplots() # create the figure\n",
        "\n",
        "sns.heatmap(corr, annot=True, cmap='Greens', annot_kws={'rotation':45}) # Draw the heatmap\n",
        "\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Design Thought process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
